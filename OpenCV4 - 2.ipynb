{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV notebook - Â©Arkaprabha Majumdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread( #reads images\n",
    "    '/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/quotes.jpg')\n",
    "#The image is HUGE ! so we need to scale it first.\n",
    "image_scaled=cv2.pyrDown(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1. Erosion and Dilation\n",
    "In openCV, for black on white text:\n",
    "    dilation thins the text\n",
    "    erosion bolds the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating kernel \n",
    "kernel = np.ones((5, 5), np.uint8) \n",
    "# Using cv2.erode() method  \n",
    "eroded = cv2.erode(image_scaled, kernel)\n",
    "cv2.imshow(\"Eroded image\",eroded)\n",
    "dilated = cv2.dilate(eroded, kernel)\n",
    "cv2.imshow(\"Dilated image\",dilated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, above... I had to pass the eroded image to the dilate function\n",
    "because the text disappears on dilating original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidenote: Do check if the image has properly loaded if you get an assertion error\n",
    "In fact, what we did above is called CLOSING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening=cv2.morphologyEx(image_scaled,cv2.MORPH_OPEN,kernel)\n",
    "closing=cv2.morphologyEx(image_scaled,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow(\"Opened image\",opening)\n",
    "cv2.imshow(\"Closed image\",closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the opened image removes the text in THIS CASE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If original text is already fat, OPEN !\n",
    "#### If original text is already thin, CLOSE !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2. Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 types of edge detection algorithms:\n",
    "    Sobel\n",
    "    Laplacian\n",
    "    Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_gray=cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/big cat.jpg',0)\n",
    "#Let's scale it down\n",
    "animal_gray=cv2.pyrDown(animal_gray)\n",
    "sobel_x = cv2.Sobel(animal_gray,cv2.CV_64F,0,1,ksize=5) #horizontal edges\n",
    "sobel_y = cv2.Sobel(animal_gray,cv2.CV_64F,1,0,ksize=5) #vertical edges\n",
    "\n",
    "#We can combine both\n",
    "sobel_both=cv2.bitwise_or(sobel_x,sobel_y)\n",
    "\n",
    "Laplacian=cv2.Laplacian(animal_gray,cv2.CV_64F) #no params\n",
    "\n",
    "canny=cv2.Canny(animal_gray,20,170)\n",
    "#values for the thresholds can be tweaked for better results\n",
    "\n",
    "\n",
    "cv2.imshow(\"SOBEL X\",sobel_x)\n",
    "cv2.imshow(\"SOBEL Y\",sobel_y)\n",
    "cv2.imshow(\"SOBEL Combined\",sobel_both)\n",
    "cv2.imshow(\"LAPLACIAN\",Laplacian)\n",
    "cv2.imshow(\"CANNY\",canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the outputs are different yet we can make it out that's a big lemur pup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4. Perspective Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import another picture for this\n",
    "book_image=cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/book of romans.jpg',0)\n",
    "book_image=cv2.resize(book_image,None,fx=.9,fy=.9)\n",
    "#The image was exceeding the size of my screen, so I scaled by .9\n",
    "cv2.imshow(\"Book of Romans\",book_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we'll note down the book corner points\n",
    "'''338,167\n",
    "315,335\n",
    "517,179\n",
    "543,338'''\n",
    "points_page=np.float32([[337,176],\n",
    "                       [315,337],\n",
    "                       [513,181],\n",
    "                       [543,339]])\n",
    "\n",
    "#then we input the points for a regular A4 page\n",
    "points_A4=np.float32([[0,0],\n",
    "                      [0,594],\n",
    "                      [420,0],\n",
    "                      [420,594]])\n",
    "\n",
    "#Next create the perspective transform matrix\n",
    "M=cv2.getPerspectiveTransform(points_page,points_A4)\n",
    "\n",
    "#Now warp!\n",
    "warped_page=cv2.warpPerspective(book_image,M,(420,594))\n",
    "\n",
    "cv2.imshow(\"Book of Romans\",book_image)\n",
    "cv2.imshow(\"Corrected book of Romans\",warped_page)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a image manipulator for our webcam.\n",
    "# Project : Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch(image):\n",
    "    #change the input image to grascale\n",
    "    image_grayscale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #gaussian blur - to denoise the image.\n",
    "    '''You can check the effect of not denoising by making the next line uncommented'''\n",
    "    denoised_img=cv2.GaussianBlur(image_grayscale,(5,5),0)\n",
    "    #denoised_img=image_grayscale\n",
    "    \n",
    "    \n",
    "    #we need to detect edges for whatever we do, so\n",
    "    edges=cv2.Canny(denoised_img,20,50)\n",
    "    \n",
    "    #apply thresholding to get various sketch effects\n",
    "    ret,mask=cv2.threshold(edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "#Next we take webcam feed as frames using VideoCapture object\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#Then we infinite loop each single frame to create video\n",
    "#Without loop, its only one image\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    cv2.imshow(\"Video Capture threshold feed\",sketch(frame))\n",
    "    if cv2.waitKey(1)==13: #13 is the Enter key. you can put any key here\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.pyrDown(cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/Crowd.jpg'))\n",
    "#This is a little tough photo because it has so many people.\n",
    "\n",
    "#So first we convert the image to grayscale\n",
    "image_grayscale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Then, to reduce noise we use Gaussian Blur\n",
    "denoised_img=cv2.GaussianBlur(image_grayscale,(5,5),0)\n",
    "\n",
    "#Detecting edges using Canny.This is an important step. Try tweaking the parameter values \n",
    "edges=cv2.Canny(denoised_img,160,200)\n",
    "\n",
    "#the findContours function in OpenCV returns a list of list of boundary points, and their hierarchy\n",
    "contours,hierarchy=cv2.findContours(edges,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "'''RETR is a retrieval parameter signifying hierarchy:\n",
    "            RETR_EXTERNAL signifies that we want the outer contours only.\n",
    "            RETR_LIST retrieves all contours.\n",
    "            RETR_COMP retrieves 2-level hierarchies.\n",
    "            RETR_TREE retrieves all hierarchies.\n",
    "'''\n",
    "\n",
    "''' CHAIN_APPROX_NONE returns all boundary points\n",
    "    CHAIN_APPROX_SIMPLE returns only corner points\n",
    "'''\n",
    "\n",
    "cv2.imshow(\"contour\",cv2.drawContours(image,contours,-1,(0,255,0),3))\n",
    "# \"-1\" gives all contours, '1' gives first contour, '2' gives second, etc...\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(image):\n",
    "    #change the input image to grascale\n",
    "    image_grayscale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #gaussian blur - to denoise the image.\n",
    "    '''You can check the effect of not denoising by making the next line uncommented'''\n",
    "    denoised_img=cv2.GaussianBlur(image_grayscale,(5,5),0)\n",
    "     \n",
    "\n",
    "    #we need to detect edges for whatever we do, so\n",
    "    edges=cv2.Canny(denoised_img,10,50)\n",
    "    \n",
    "    #contour\n",
    "    contours,hierarchy=cv2.findContours(edges,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "#Next we take webcam feed as frames using VideoCapture object\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#Then we infinite loop each single frame to create video\n",
    "#Without loop, its only one image\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    contours=contour(frame)\n",
    "    cv2.imshow(\"contour\",cv2.drawContours(frame,contours,-1,(0,255,0),3))\n",
    "    if cv2.waitKey(1)==13: #13 is the Enter key. you can put any key here\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like that...we can now apply every effect we learn to our webcam !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
