{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV notebook - Â©Arkaprabha Majumdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1. Sorting Contours\n",
    "This is of two kinds:\n",
    "Eliminating smaller contours, and contour in specific orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "image=cv2.pyrDown(cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/quotes.jpg'))\n",
    "\n",
    "black_bg=np.zeros(image.shape)\n",
    "\n",
    "grayscale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edges=cv2.Canny(grayscale,252,255)\n",
    "\n",
    "contours,hierarchy=cv2.findContours(edges,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "print(len(contours))\n",
    "\n",
    "cv2.drawContours(black_bg,[x for x in contours if cv2.contourArea(x)>10],-1,(0,255,0),3)\n",
    "cv2.imshow(\"Contours on black\",black_bg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1847.0, 1169.0, 1125.0, 980.0, 849.0, 736.0, 476.5, 442.5, 427.5, 409.5, 297.0, 254.0, 208.0, 172.0, 153.0, 150.0, 148.0, 142.0, 131.0, 129.0, 127.0, 113.5, 109.0, 104.0, 89.5, 77.5, 57.0, 46.0, 40.0, 29.0, 22.0, 20.5, 17.5, 11.0, 10.0, 10.0, 7.5, 4.0, 4.0, 4.0, 4.0, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def getArea(contours):\n",
    "    all_area=[]\n",
    "    for cnt in contours:\n",
    "        all_area.append(cv2.contourArea(cnt))\n",
    "    return all_area\n",
    "\n",
    "sorted_contours=sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "print(getArea(sorted_contours))\n",
    "\n",
    "for c in sorted_contours:\n",
    "    if getArea([c])[0]>100:\n",
    "        cv2.drawContours(image,c,-1,(255,0,0),3)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.imshow(\"Contour by area\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArea([sorted_contours[2]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.pyrDown(cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/quotes.jpg'))\n",
    "\n",
    "grayscale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edges=cv2.Canny(grayscale,252,255)\n",
    "\n",
    "contours,hierarchy=cv2.findContours(edges,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#If we dont re import the image, the annotations get stored on the image\n",
    "def x_coord(contour):\n",
    "    #returns the x coordinate of the contour centroid\n",
    "    if cv2.contourArea(contour)>10:\n",
    "        M=cv2.moments(contour)\n",
    "        return int(M['m10']/M['m00'])\n",
    "    \n",
    "def label_center(image,c,i):\n",
    "    #places a red circle on the contour centroid\n",
    "    M=cv2.moments(c)\n",
    "    if M['m00']>0:\n",
    "        cx=int(M['m10']/M['m00'])\n",
    "        cy=int(M['m01']/M['m00'])\n",
    "        cv2.circle(image,(cx,cy),10,(0,0,255),-1)\n",
    "        return image\n",
    "\n",
    "#Compute centroid and draw image\n",
    "for (i,c) in enumerate(contours):\n",
    "    orig=label_center(image,c,i)\n",
    "    \n",
    "#print(contours)\n",
    "#Sort left to right\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "cnt_L2R,boundingRect=sort_contours(contours)\n",
    "\n",
    "for (i,c) in enumerate(list(cnt_L2R)):\n",
    "    M=cv2.moments(c)\n",
    "    if M['m00']>0:\n",
    "        cx=int(M['m10']/M['m00'])\n",
    "        cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(image,str(i+1),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow(\"L2R contour\",image)\n",
    "        key=cv2.waitKey(0)\n",
    "        if key==27: #Esc key to stop\n",
    "            break\n",
    "        elif key==13:\n",
    "            (x,y,w,h) = boundingRect[i]\n",
    "            print(boundingRect[i])\n",
    "            #Then we crop each contour and save them in separate files\n",
    "            cropped=image[y:y+h,x:x+w]\n",
    "            image_name=\"output_cropped_shape_\"+str(i+1)+\".jpg\"\n",
    "            cv2.imwrite(image_name,cropped)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the key number of any key on your keyboard, use a function like below to print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"img=cv2.pyrDown(cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/bear.jpg'))\\nwhile(1):\\n    cv2.imshow('img',img)\\n    k = cv2.waitKey(33)\\n    if k==27:    # Esc key to stop\\n        break\\n    elif k==-1:  # normally -1 returned,so don't print it\\n        continue\\n    else:\\n        print(k) # else print its value\\ncv2.destroyAllWindows()\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''img=cv2.pyrDown(cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/bear.jpg'))\n",
    "while(1):\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(33)\n",
    "    if k==27:    # Esc key to stop\n",
    "        break\n",
    "    elif k==-1:  # normally -1 returned,so don't print it\n",
    "        continue\n",
    "    else:\n",
    "        print(k) # else print its value\n",
    "cv2.destroyAllWindows()'''\n",
    "\n",
    "#Space=32\n",
    "#Esc=27\n",
    "#Enter=13\n",
    "#backspace=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The moments function in openCV gives 10 values of spatial moments, 7 values of central moments and 7 values of central norm moments. All other values are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2. Contour Approximation\n",
    "This approximates a contour. It is particularly useful if your image has small gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/animals-better.jpg')\n",
    "orig_image=image.copy()\n",
    "\n",
    "#cv2.imshow(\"Original image\",orig_image)\n",
    "\n",
    "grayscale=cv2.cvtColor(orig_image,cv2.COLOR_BGR2GRAY)\n",
    "denoised_image=cv2.GaussianBlur(grayscale,(5,5),0)\n",
    "\n",
    "edges=cv2.Canny(denoised_image,100,150)\n",
    "cv2.imshow(\"Canny\",edges)\n",
    "\n",
    "cnt,hier=cv2.findContours(edges,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for c in cnt:\n",
    "    x,y,w,h= cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "    cv2.imshow(\"Bounding Rectangle\",orig_image)\n",
    "\n",
    "black_bg=np.zeros(orig_image.shape)\n",
    "    \n",
    "for c in cnt:\n",
    "    accuracy=0.03*cv2.arcLength(c,True)\n",
    "    approx=cv2.approxPolyDP(c,accuracy,True)\n",
    "    cv2.drawContours(black_bg,[approx],0,(0,255,0),1)\n",
    "    cv2.imshow(\"Approx poly DP\",black_bg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex Hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to contour approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(cnt)\n",
    "contours=sorted(cnt, key=cv2.contourArea,reverse=False)[:n]\n",
    "\n",
    "#iterate through and draw hull\n",
    "for c in contours:\n",
    "    hull=cv2.convexHull(c)\n",
    "    cv2.drawContours(image,[hull],0,(0,0,255),1)\n",
    "    cv2.imshow(\"Convex Hull\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3. Matching Shapes\n",
    "This is a basic identification which can be further used to identify complex shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "#First we create a template contour to match\n",
    "\n",
    "hexagon_input=cv2.imread(\"/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/hexagon.jpg\") #basic template\n",
    "gray=cv2.cvtColor(hexagon_input,cv2.COLOR_BGR2GRAY)\n",
    "gray=cv2.erode(gray,(5,5))\n",
    "#cv2.imshow(\"dfdg\",gray)\n",
    "_,thresh=cv2.threshold(gray,150,255,cv2.THRESH_BINARY_INV)\n",
    "template_cnt,hier=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "sorted_cont=sorted(template_cnt,key=cv2.contourArea,reverse=True)\n",
    "cv2.drawContours(hexagon_input,sorted_cont[0],-1,(0,0,255),3)\n",
    "cv2.imshow(\"threshold hex\",hexagon_input)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.pyrDown(cv2.imread(\"/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/shape scenery.jpg\"))\n",
    "blurred=cv2.GaussianBlur(image,(3,3),0)\n",
    "black_bg=np.zeros(image.shape)\n",
    "canny=cv2.Canny(blurred,50,150)\n",
    "cv2.imshow(\"ssg\",canny)\n",
    "contours=cv2.findContours(canny,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "for c in [x for x in contours if cv2.contourArea(x)>100]:\n",
    "    match=cv2.matchShapes(sorted_cont[0],c,1,0.0)\n",
    "    if match < 0.5 :\n",
    "        closest_contour.append(c)\n",
    "for c in closest_contour:\n",
    "    hull=cv2.convexHull(c)\n",
    "    cv2.drawContours(image,[hull],-1,(248,255,9),3)\n",
    "    cv2.imshow(\"Output_\",image)\n",
    "    k=cv2.waitKey(0)\n",
    "    if k==27: #Esc key to stop\n",
    "        break\n",
    "    elif k==13:\n",
    "        continue\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Identify and name shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "7\n",
      "5\n",
      "16\n",
      "14\n",
      "6\n",
      "10\n",
      "11\n",
      "1\n",
      "2\n",
      "10\n",
      "13\n",
      "6\n",
      "8\n",
      "6\n",
      "12\n",
      "15\n",
      "16\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "10\n",
      "2\n",
      "12\n",
      "8\n",
      "5\n",
      "14\n",
      "12\n",
      "1\n",
      "3\n",
      "4\n",
      "14\n",
      "12\n",
      "2\n",
      "2\n",
      "2\n",
      "15\n",
      "5\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "new_img=cv2.imread(\"/home/arkaprabham/Desktop/Deep_Learning_Udemy/img/3d-Shapes.jpg\")[:532,:] #crop words out\n",
    "copied=new_img.copy()\n",
    "cv2.imshow(\"Project 2\",new_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "grayscale=cv2.cvtColor(new_img,cv2.COLOR_BGR2GRAY)\n",
    "blurred=cv2.GaussianBlur(grayscale,(5,5),cv2.BORDER_DEFAULT)\n",
    "canny=cv2.Canny(blurred,100,200)\n",
    "cv2.imshow(\"Canny\",canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours=cv2.findContours(canny,2,1)[0]\n",
    "black_bg=np.zeros(new_img.shape)\n",
    "for c in contours:\n",
    "    #to get approximate polygons\n",
    "    approx=cv2.approxPolyDP(c,0.01*cv2.arcLength(c,True),True)\n",
    "    print(len(approx))\n",
    "    #print(\"next\")\n",
    "    if len(approx)==6:\n",
    "        cv2.drawContours(black_bg,[c],0,(83,83,233),-1)\n",
    "        M=cv2.moments(c)\n",
    "        if M['m00']>0:\n",
    "            cx=int(M['m10']/M['m00'])\n",
    "            cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(black_bg,\"hexagon\",(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,.2,(255,255,255),1)\n",
    "\n",
    "    elif len(approx)==5:\n",
    "        cv2.drawContours(black_bg,[c],0,(233,163,83),-1)\n",
    "        M=cv2.moments(c)\n",
    "        if M['m00']>0:\n",
    "            cx=int(M['m10']/M['m00'])\n",
    "            cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(black_bg,\"pentagon\",(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        \n",
    "    elif len(approx)==4:\n",
    "        cv2.drawContours(black_bg,[c],0,(63,182,50),-1)\n",
    "        M=cv2.moments(c)\n",
    "        if M['m00']>0:\n",
    "            cx=int(M['m10']/M['m00'])\n",
    "            cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(black_bg,\"parallelogram\",(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        \n",
    "    elif len(approx)>15:\n",
    "        cv2.drawContours(black_bg,[c],0,(0,128,255),-1)\n",
    "        M=cv2.moments(c)\n",
    "        if M['m00']>0:\n",
    "            cx=int(M['m10']/M['m00'])\n",
    "            cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(black_bg,\"circle\",(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        \n",
    "cv2.imshow(\"found shapes\",black_bg)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer depends on the presence of other shapes, level of noise if any and invariance you want to provide for (e.g. rotation, scaling, etc).\n",
    "These requirements will define not only the algorithm but also required pre-procesing stages to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
